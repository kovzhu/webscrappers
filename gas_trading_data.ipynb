{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gas trading data.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN4o5PnizrPQ104ppXYsSbx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kovzhu/webscrappers/blob/master/gas_trading_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "-7b41-NnDNpB",
        "outputId": "823cf216-757c-4b1e-e855-15b6931fa210"
      },
      "source": [
        "# Note to use it:\n",
        "# 1， Chongqing data: input the range of dates to download the data\n",
        "# 2, Shanghai data: input the type of data for the wareid parameters - 3 for LNG, 6 for pipeline, and the number of pages you want to download\n",
        "\n",
        "import time\n",
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "import sys\n",
        "from bs4 import BeautifulSoup as bs\n",
        "import re\n",
        "from google.colab import files\n",
        "\n",
        "def gettime():\n",
        "    return int(round(time.time() * 1000))\n",
        "\n",
        "\n",
        "def getResponse(url, headers, params):\n",
        "    try:\n",
        "        response = requests.request(\"GET\", url, headers=headers, params=params)\n",
        "        reqIsJson = False\n",
        "\n",
        "        if \"application/json\" in response.headers.get('content-type'):\n",
        "            reqIsJson = True\n",
        "\n",
        "        if response.status_code == 200 and reqIsJson == True:\n",
        "            return response\n",
        "\n",
        "        if response.status_code == 200 and reqIsJson == False:\n",
        "            print(\"Unsupported content type received : \", response.headers.get('content-type'))\n",
        "            return response\n",
        "\n",
        "        print('Status Code: ' + str(response.status_code))\n",
        "\n",
        "        if response.status_code == 400:\n",
        "            print(\"The server could not understand your request, check the syntax for your query.\")\n",
        "            print('Error Message: ' + str(response.json()))\n",
        "        elif response.status_code == 401:\n",
        "            print(\"Login failed, please check your user name and password.\")\n",
        "        elif response.status_code == 403:\n",
        "            print(\"You are not entitled to this data.\")\n",
        "        elif response.status_code == 404:\n",
        "            print(\"The URL you requested could not be found or you have an invalid view name.\")\n",
        "        elif response.status_code == 500:\n",
        "            print(\"The server encountered an unexpected condition which prevented it from fulfilling the request.\")\n",
        "            print(\"Error Message: \" + str(response.json()))\n",
        "            print(\"If this persists, please contact customer care.\")\n",
        "        else:\n",
        "            print(\"Error Message: \" + str(response.json()))\n",
        "    except:\n",
        "        sys.exit()\n",
        "\n",
        "\n",
        "def get_Shanghai_data(pages):\n",
        "    headers = {\n",
        "        'User-Agent': r'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36',\n",
        "        'Referer': r'https://www.shpgx.com/html/gdtrqsj.html',\n",
        "        'Connection': r'keep-alive',\n",
        "        'Content-Type': r'application/x-www-form-urlencoded; charset=UTF-8'}\n",
        "    s = requests.session()\n",
        "    table = pd.DataFrame()\n",
        "    for i in range(pages):\n",
        "        params = {\n",
        "            # 'wareid': 6, # for pipeline deals\n",
        "            'wareid': 3,  # for LNG deals\n",
        "            'cd': None,\n",
        "            'starttime': None,\n",
        "            'endtime': None,\n",
        "            'start': 0 + 25 * i,\n",
        "            'length': 25,\n",
        "            'ts': str(gettime())}\n",
        "\n",
        "        payload = {\n",
        "            'wareid': 6,\n",
        "            'cd': None,\n",
        "            'starttime': None,\n",
        "            'endtime': None,\n",
        "            'start': 0,\n",
        "            'length': 25,\n",
        "            'ts': str(gettime())}\n",
        "\n",
        "        # url = r'https://www.shpgx.com/html/gdtrqsj.html'\n",
        "        url = r'https://www.shpgx.com/marketstock/dataList'\n",
        "        response = s.get(url, headers=headers, params=params).text.encode('utf-8')\n",
        "        # data = getResponse(url,headers, params).text.encode('utf8')\n",
        "        data = pd.DataFrame(json.loads(response)['root'])\n",
        "        rows = len(data.index)\n",
        "        for i in range(rows):\n",
        "            df = pd.DataFrame.from_dict(\n",
        "                {'挂牌价': data.iloc[i]['basename'],\n",
        "                 '成交价': data.iloc[i]['contprice'],\n",
        "                 '价格单位':data.iloc[i]['priceunit'],\n",
        "                 '挂牌量': data.iloc[i]['basenum'],\n",
        "                 '成交量': data.iloc[i]['dealnum'],\n",
        "                 '成交量单位': data.iloc[i]['countunit'],\n",
        "                 '种类': data.iloc[i]['warekind'],\n",
        "                 '交易方式': data.iloc[i]['ordmod'],\n",
        "                 '开始日期': data.iloc[i]['startdate'],\n",
        "                 '交收截至日': data.iloc[i]['enddate'],\n",
        "                 '交收地': data.iloc[i]['jsd'],\n",
        "                 '输入 时间': data.iloc[i]['createTime'],\n",
        "                 '信息更新时间': data.iloc[i]['updateTime'],\n",
        "                 '挂牌日期': data.iloc[i]['orderdate']}, orient='index')\n",
        "            table = pd.merge(table, df, how='outer', left_index=True, right_index=True)\n",
        "    return table.T\n",
        "\n",
        "def get_Chongqing_pages(start_date, end_date):\n",
        "    url = 'https://www.chinacqpgx.com/jyxx/index.php?type=0&area=&t1=' + str(start_date)+'&t2='+str(end_date)\n",
        "    soup = bs(requests.get(url).text, features=\"lxml\")\n",
        "    page_codes = soup.find_all(name='div', attrs={'class': 'met_pager gm-pager'})[0]\n",
        "    pages = int(re.findall('第/(\\d*)页', page_codes.text)[0])\n",
        "    return pages\n",
        "\n",
        "# def get_shanghai_LNG_pages():\n",
        "#     url = r'https://www.shpgx.com/html/yhtrqsj.html'\n",
        "#     soup = bs(requests.get(url).text, features=\"lxml\")\n",
        "    \n",
        "    \n",
        "    \n",
        "def get_Chongqing_data(start_date='20201207', end_date='20210114'):\n",
        "    headers = {\n",
        "        'User-Agent': r'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36',\n",
        "        'Referer': r'https://www.chinacqpgx.com/jyxx/index.php?type=0&area=&t1=20201201&t2=20201206',\n",
        "        'Connection': r'keep-alive',\n",
        "        'Cookie': r'Cookie: zero_areaArr3=%5B%22%E5%9B%9B%E5%B7%9D%22%2C%22%E5%8C%97%E4%BA%AC%22%2C%22%E9%87%8D%E5%BA%86%22%2C%22%E5%AE%81%E5%A4%8F%22%2C%22%E5%B9%BF%E5%B7%9E%22%2C%22%E9%9D%92%E6%B5%B7%22%2C%22%E5%8D%97%E5%AE%81%22%2C%22%E4%B8%8A%E6%B5%B7%22%2C%22%E5%86%85%E8%92%99%E5%8F%A4%22%2C%22%E4%BA%91%E5%8D%97%22%2C%22%E7%94%98%E8%82%83%22%2C%22%E6%96%B0%E7%96%86%22%2C%22%E9%99%95%E8%A5%BF%22%2C%22%E6%B9%96%E5%8D%97%22%2C%22%E8%B4%B5%E5%B7%9E%22%2C%22%E6%B1%9F%E8%A5%BF%22%2C%22%E6%B9%96%E5%8C%97%22%2C%22%E5%B9%BF%E8%A5%BF%22%2C%22%E5%90%89%E6%9E%97%22%2C%22%E8%BE%BD%E5%AE%81%22%2C%22%E5%A4%A9%E6%B4%A5%22%2C%22%E5%AE%89%E5%BE%BD%22%2C%22%E5%B9%BF%E4%B8%9C%22%2C%22%E5%B1%B1%E8%A5%BF%22%2C%22%E6%B1%9F%E8%8B%8F%22%2C%22%E6%B2%B3%E5%8C%97%22%2C%22%E5%B1%B1%E4%B8%9C%22%2C%22%E6%B2%B3%E5%8D%97%22%2C%22%E7%A6%8F%E5%BB%BA%22%2C%22%E5%85%A8%E4%B8%AD%E5%9B%BD%22%5D; Hm_lvt_f81598e2508cd3d34d620f5689165095=1610620639; Hm_lpvt_f81598e2508cd3d34d620f5689165095=1610620793'}\n",
        "    pages = get_Chongqing_pages(start_date, end_date)\n",
        "    page_data = pd.DataFrame()\n",
        "    for i in range(1, pages + 1):\n",
        "        params = {\n",
        "            'type': 'all',\n",
        "            'area': None,\n",
        "            't1': start_date,\n",
        "            't2': end_date,\n",
        "            'p': i\n",
        "        }\n",
        "        url = r'https://www.chinacqpgx.com/jyxx/index.php'\n",
        "        s = requests.session()\n",
        "        table = pd.DataFrame()\n",
        "        # response = s.get(url, headers=headers, params=params).text.encode('utf-8')\n",
        "        response = s.get(url, headers=headers, params=params)\n",
        "        soup = bs(response.text, features='lxml')\n",
        "        code = soup.find_all(name='div', attrs={'class': 'trade-content'})[0].find_all('li')\n",
        "        rows = len(code) - 6\n",
        "\n",
        "        for i in range(rows):\n",
        "            row_data = pd.DataFrame.from_dict({\n",
        "                code[0].text: code[6 + i].text.splitlines()[2],\n",
        "                code[1].text: code[6 + i].text.splitlines()[3],\n",
        "                code[2].text: code[6 + i].text.splitlines()[4],\n",
        "                code[3].text: code[6 + i].text.splitlines()[5],\n",
        "                code[4].text: code[6 + i].text.splitlines()[6],\n",
        "                code[5].text: code[6 + i].text.splitlines()[7]\n",
        "\n",
        "            }, orient='index')\n",
        "            page_data = pd.merge(page_data, row_data, how='outer', left_index=True, right_index=True)\n",
        "    return page_data.T\n",
        "\n",
        "\n",
        "def main():\n",
        "    ChongQing_data = get_Chongqing_data('20210315','20210401')\n",
        "    ChongQing_data.to_excel('Chongqing data.xlsx')\n",
        "\n",
        "    Shanghai_data = get_Shanghai_data(2)\n",
        "    Shanghai_data.to_excel('shanghai data.xlsx')\n",
        "    \n",
        "    files.download('Chongqing data.xlsx')\n",
        "    files.download('shanghai data.xlsx')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_4b6bfeca-12ef-4684-92ca-875360c3f1e7\", \"Chongqing data.xlsx\", 8220)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_f2799384-49ff-4575-9d98-20c186938b1c\", \"shanghai data.xlsx\", 8224)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}